use miette::Result;
use chumsky::{input::Input, span::SimpleSpan, Parser};

use self::{ast::ast, token::Token};

mod token;
mod ast;
mod divs;
mod stat;

/// Exports.
pub use ast::Ast;
pub(crate) use stat::Stat;

/// Simple span types for use in AST items throughout the parser.
pub type Span = SimpleSpan<usize>;
pub type Spanned<T> = (T, Span);

// The type of the input that our internal parsers operate on.
// The input is the `&[(Token, Span)]` token buffer generated by the lexer, wrapped in a `SpannedInput`
// which 'splits' it apart into its constituent parts, tokens and spans, for chumsky to understand.
type ParserInput<'tokens, 'src> =
    chumsky::input::SpannedInput<Token<'src>, Span, &'tokens [(Token<'src>, Span)]>;

pub fn parse(input: &str) -> Result<Ast> {
    // Extract tokens from input.
    let lexer = token::lexer();
    let (toks, errs) = lexer.parse(input).into_output_errors();
    errs.into_iter()
        .map(|e| e.map_token(|c| c.to_string()))
        .for_each(|e| {
            println!("{}", e.reason().to_string());
        });

    // Parse the AST.
    let toks = toks.unwrap();
    println!("toks: {:#?}", toks);

    let ast_parse = ast().parse(toks.as_slice().spanned((input.len()..input.len()).into()));
    let (ast, errs) = ast_parse.into_output_errors();
    errs.into_iter()
        .map(|e| e.map_token(|c| format!("{:#?}", c)))
        .for_each(|e| {
            println!("{}", e.reason().to_string());
        });

    println!("ast: {:#?}", ast.as_ref().unwrap());
        
    Ok(ast.unwrap())
}